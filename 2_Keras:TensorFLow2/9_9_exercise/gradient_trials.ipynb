{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def grad( y, x ):\n",
    "    return Lambda( lambda z: K.gradients( z[ 0 ], z[ 1 ] ), output_shape = [1] )( [ y, x ] )\n",
    "\n",
    "def network( i ):\n",
    "    a = Lambda(lambda x: K.log( x + 2 ) )( i )\n",
    "    return a\n",
    "\n",
    "fixed_input = Input(shape=(1,))\n",
    "# double = Input(tensor=tf.Variable( [ 2.0 ] ) )\n",
    "unit_activation = tf.keras.initializers.Ones()\n",
    "dense_dummy_layer = keras.layers.Dense(units=1,use_bias=False,\n",
    "                                      kernel_initializer=unit_activation)(fixed_input)\n",
    "# a = network(fixed_input)\n",
    "a = network(dense_dummy_layer)\n",
    "\n",
    "b = grad( a, fixed_input )\n",
    "c = grad( b, fixed_input )\n",
    "# d = grad( c, fixed_input )\n",
    "# e = grad( d, fixed_input )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1],\n",
    "            [2],\n",
    "            [3]])\n",
    "model = Model( inputs = [ fixed_input], outputs = [ a,b] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 1)]          0           lambda[0][0]                     \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.0986123],\n",
      "       [1.3862944],\n",
      "       [1.609438 ]], dtype=float32), [array([[0.33333334],\n",
      "       [0.25      ],\n",
      "       [0.2       ]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "print( model.predict( x, steps = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681098 0.3333333333333333 -0.1111111111111111\n",
      "1.3862943611198906 0.25 -0.0625\n",
      "1.6094379124341003 0.2 -0.04\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(np.log(i+2),1/(i+2),-1/(i+2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying new things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def grad( y, x ):\n",
    "    return Lambda( lambda z: K.gradients( z[ 0 ], z[ 1 ] ))( [ y, x\n",
    "                                                             ] )\n",
    "\n",
    "def network( i ):\n",
    "    a = Lambda(lambda x: K.log( x + 2 ) )( i )\n",
    "    return a\n",
    "\n",
    "fixed_input = Input(shape=(2,))\n",
    "# double = Input(tensor=tf.Variable( [ 2.0 ] ) )\n",
    "unit_activation = tf.keras.initializers.Ones()\n",
    "# dense_dummy_layer = keras.layers.Dense(units=2,use_bias=False,\n",
    "#                                       kernel_initializer=unit_activation)(fixed_input)\n",
    "# a = network(fixed_input)\n",
    "# a = network(dense_dummy_layer)\n",
    "a = Lambda(lambda x: x[:,0]*x[:,1]) (fixed_input)\n",
    "\n",
    "# taking derrivative with respect to secon variable\n",
    "b = keras.layers.Lambda(lambda z: K.gradients(z[0],z[1])) ([a,fixed_input])\n",
    "# c = grad( b, fixed_input )\n",
    "# d = grad( c, fixed_input )\n",
    "# e = grad( d, fixed_input )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,4],\n",
    "            [2,5],\n",
    "            [3,6]])\n",
    "model = Model( inputs = [ fixed_input], outputs = [a, b] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None,)              0           input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             [(None, 2)]          0           lambda_113[0][0]                 \n",
      "                                                                 input_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4., 10., 18.], dtype=float32), [array([[4., 1.],\n",
      "       [5., 2.],\n",
      "       [6., 3.]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "print( model.predict( x, steps = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09861228866811 0.3333333333333333 -0.1111111111111111\n",
      "3.386294361119891 0.25 -0.0625\n",
      "4.6094379124341005 0.2 -0.04\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(np.log(i+2) + i,1/(i+2),-1/(i+2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def hes( y, x ):\n",
    "    return Lambda( lambda z: tf.hessians( z[ 0 ], z[ 1 ] ), output_shape = [1] )( [ y, x ] )\n",
    "\n",
    "def network( i ):\n",
    "    a = Lambda(lambda x: K.log( x + 2 ) )( i )\n",
    "    return a\n",
    "\n",
    "fixed_input = Input(shape=(1,))\n",
    "# double = Input(tensor=tf.Variable( [ 2.0 ] ) )\n",
    "unit_activation = tf.keras.initializers.Ones()\n",
    "dense_dummy_layer = keras.layers.Dense(units=1,use_bias=False,\n",
    "                                      kernel_initializer=unit_activation)(fixed_input)\n",
    "# a = network(fixed_input)\n",
    "a = network(dense_dummy_layer)\n",
    "\n",
    "b = hes( a, fixed_input )\n",
    "# c = grad( b, fixed_input )\n",
    "# d = grad( c, fixed_input )\n",
    "# e = grad( d, fixed_input )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1],\n",
    "            [2],\n",
    "            [3]])\n",
    "model = Model( inputs = [ fixed_input], outputs = [b] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               [(None, 1, None, 1)] 0           lambda_5[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[-0.11111112],\n",
      "         [ 0.        ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [-0.0625    ],\n",
      "         [ 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.        ],\n",
      "         [ 0.        ],\n",
      "         [-0.04      ]]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print( model.predict( x, steps = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681098 0.3333333333333333 -0.1111111111111111\n",
      "1.3862943611198906 0.25 -0.0625\n",
      "1.6094379124341003 0.2 -0.04\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(np.log(i+2),1/(i+2),-1/(i+2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything inside a custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.input_layer = Lambda(lambda x: K.log( x+2  ) )\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "        return keras.layers.Lambda(lambda x: K.gradients(x[0],x[1])) ([func,argm])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.input_layer(inputs)\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "        return Z_1\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.],\n",
    "            [1],\n",
    "            [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.5       ],\n",
       "        [0.33333334],\n",
       "        [0.25      ]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient of multi-dimensional function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "#         self.input_layer = Lambda(lambda x: K.log(x[:,0:1]+2) + x[:,1:2]**2 * x[:,2:3] + x[:,2:3]**3  )\n",
    "#         self.input_layer = Lambda(lambda x: x[:,0:1] * x[:,1:2] * x[:,2:3]  )\n",
    "        self.input_layer = Lambda(lambda x:x[0]*x[1])\n",
    "#         self.grad_layer = Lambda(lambda x: K.gradients(x[0],x[1][:,0:1]))\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "#         x_1 = self.input_copy[:,0:1]\n",
    "# #         x_2 = argm[1]\n",
    "# #         x_3 = argm[2]\n",
    "#         print(\"x_1_type is \",type(x_1))\n",
    "#         print(x_1)\n",
    "        return keras.layers.Lambda(lambda x: tf.gradients(x[0],x[1][0])) ([func,argm])\n",
    "#         return K.gradients(func,argm)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_1,input_2 = inputs\n",
    "        Z = self.input_layer([input_1,input_2])\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "#         Z_2 = self.findGrad(Z_1,inputs)\n",
    "        return  Z_1\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.array([[0.],\n",
    "            [1.],\n",
    "            [2]])\n",
    "x_2 = np.array([[3.],\n",
    "            [4.],\n",
    "            [5]])\n",
    "# x = np.array([0.,1,2])\n",
    "# x = x[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.],\n",
       "        [4.],\n",
       "        [5.]], dtype=float32)]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = custom_model.predict(x=[x_1,x_2])\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian of multi-dimensional function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "#         self.input_layer = Lambda(lambda x: K.log(x[:,0:1]+2) + x[:,1:2]**2 * x[:,2:3] + x[:,2:3]**3  )\n",
    "#         self.input_layer = Lambda(lambda x: x[:,0:1] * x[:,1:2] * x[:,2:3]  )\n",
    "        self.input_layer = Lambda(lambda x:x[0] * x[1]*x[2])\n",
    "#         self.grad_layer = Lambda(lambda x: K.gradients(x[0],x[1][:,0:1]))\n",
    "\n",
    "    def findGrad(self,func,argm):\n",
    "#         x_1 = self.input_copy[:,0:1]\n",
    "# #         x_2 = argm[1]\n",
    "# #         x_3 = argm[2]\n",
    "#         print(\"x_1_type is \",type(x_1))\n",
    "#         print(x_1)\n",
    "#         return keras.layers.Lambda(lambda x: [tf.gradients(x[0],input_dim) for input_dim in argm]) ([func,argm])\n",
    "        return keras.layers.Lambda(lambda x: tf.gradients(x[0],x[1][0], unconnected_gradients='zero') ) ([func,argm])\n",
    "#         return K.gradients(func,argm)\n",
    "    def findSecGrad(self,func,argm):\n",
    "        return keras.layers.Lambda(lambda x: tf.gradients(x[0],x[1], \n",
    "                                                          stop_gradients=[x[1]],\n",
    "                                                          unconnected_gradients='zero') ) ([func,argm])\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_1,input_2,input_3 = inputs\n",
    "#         Z = self.input_layer([input_1, input_2, input_3])\n",
    "        Z = self.input_layer(inputs)\n",
    "        Z_1 = self.findGrad(Z,inputs)\n",
    "        #     return self.dense2(x)\n",
    "        #     print(\"\\n\\n\\n this is the answer:\",self.square_layer(inputs))\n",
    "        #     print(\"hre is a break\")\n",
    "        Z_2 = self.findSecGrad(Z_1, input_3)\n",
    "        return  Z_2\n",
    "\n",
    "\n",
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.array([[0.],\n",
    "            [1.],\n",
    "            [2]])\n",
    "x_2 = np.array([[3.],\n",
    "            [4.],\n",
    "            [5]])\n",
    "x_3 = np.array([[4.],\n",
    "            [5.],\n",
    "            [6]])\n",
    "# x = np.array([0.,1,2])\n",
    "# x = x[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.],\n",
       "        [4.],\n",
       "        [5.]], dtype=float32)]"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = custom_model.predict(x=[x_1,x_2,x_3])\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note for finding  gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can use lambda layers to find gradient with respect to different dimension of input like x,y,z,t.\n",
    "2. If we feed the input as one single block of array(np,tf), then there is problem in using tf.gradients(function,input), since the returned gradient is some kind of sum of gradients in different dim. Please see the tf.gradients() manual.\n",
    "3. A work around will be to feed the different attributes(features) of the data as different inputs so we can find the partial derrivative with respect to each input dim without a problem. Please see the section on graddient of multi-dim function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regarding second gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Seems to be working fine except for some weird instances where None is returned and there is exception thrown while converting this None to a tensor.\n",
    "2. Key point being using the notes above to find the gradient with respect to different input separately and then finally use another lambda layer to find partial derrivative of each of the partial derrivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next thing to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Write an example (Model class) to find the laplacian of the incoming layer__\n",
    "2. Go back to the original poisson problem and use the gradient and laplacian layers from this example to implement the PINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
